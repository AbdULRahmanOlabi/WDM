{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read The DataSet.\n",
    "df = pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show All Columns.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Unnecessary Column From The DataSet.  \n",
    "df=df.drop(['region', 'region_url', 'VIN','url','image_url','description','county'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Missing Value.\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79016, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing The DataFrame Shape.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79016 entries, 31 to 426836\n",
      "Data columns (total 19 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            79016 non-null  int64  \n",
      " 1   price         79016 non-null  int64  \n",
      " 2   year          79016 non-null  float64\n",
      " 3   manufacturer  79016 non-null  object \n",
      " 4   model         79016 non-null  object \n",
      " 5   condition     79016 non-null  object \n",
      " 6   cylinders     79016 non-null  object \n",
      " 7   fuel          79016 non-null  object \n",
      " 8   odometer      79016 non-null  float64\n",
      " 9   title_status  79016 non-null  object \n",
      " 10  transmission  79016 non-null  object \n",
      " 11  drive         79016 non-null  object \n",
      " 12  size          79016 non-null  object \n",
      " 13  type          79016 non-null  object \n",
      " 14  paint_color   79016 non-null  object \n",
      " 15  state         79016 non-null  object \n",
      " 16  lat           79016 non-null  float64\n",
      " 17  long          79016 non-null  float64\n",
      " 18  posting_date  79016 non-null  object \n",
      "dtypes: float64(4), int64(2), object(13)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Showing The Info of The DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'price', 'year', 'manufacturer', 'model', 'condition',\n",
       "       'cylinders', 'fuel', 'odometer', 'title_status', 'transmission',\n",
       "       'drive', 'size', 'type', 'paint_color', 'state', 'lat', 'long',\n",
       "       'posting_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing The Column-Name in The DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries For Using LabelEncoder.\n",
    "from sklearn import preprocessing\n",
    "# LabelEncoder Can Be Used to Normalize Labels.\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Label Encoder and Return Encoded Labels.\n",
    "df[['size','manufacturer', 'model', 'condition','cylinders', 'fuel', 'title_status', 'transmission','drive', 'type', 'paint_color', 'state',\n",
    "       'posting_date']] = df[['size','manufacturer', 'model', 'condition','cylinders', 'fuel', 'title_status', 'transmission','drive','type', 'paint_color', 'state',\n",
    "       'posting_date']].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Features By Scaling Each Feature to a Given Range.\n",
    "df[\"odometer\"] = np.sqrt(preprocessing.minmax_scale(df[\"odometer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "price           0\n",
       "year            0\n",
       "manufacturer    0\n",
       "model           0\n",
       "condition       0\n",
       "cylinders       0\n",
       "fuel            0\n",
       "odometer        0\n",
       "title_status    0\n",
       "transmission    0\n",
       "drive           0\n",
       "size            0\n",
       "type            0\n",
       "paint_color     0\n",
       "state           0\n",
       "lat             0\n",
       "long            0\n",
       "posting_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure That There are No Null Values Left in The DataFrame.\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79016 entries, 31 to 426836\n",
      "Data columns (total 19 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            79016 non-null  int64  \n",
      " 1   price         79016 non-null  int64  \n",
      " 2   year          79016 non-null  float64\n",
      " 3   manufacturer  79016 non-null  int32  \n",
      " 4   model         79016 non-null  int32  \n",
      " 5   condition     79016 non-null  int32  \n",
      " 6   cylinders     79016 non-null  int32  \n",
      " 7   fuel          79016 non-null  int32  \n",
      " 8   odometer      79016 non-null  float64\n",
      " 9   title_status  79016 non-null  int32  \n",
      " 10  transmission  79016 non-null  int32  \n",
      " 11  drive         79016 non-null  int32  \n",
      " 12  size          79016 non-null  int32  \n",
      " 13  type          79016 non-null  int32  \n",
      " 14  paint_color   79016 non-null  int32  \n",
      " 15  state         79016 non-null  int32  \n",
      " 16  lat           79016 non-null  float64\n",
      " 17  long          79016 non-null  float64\n",
      " 18  posting_date  79016 non-null  int32  \n",
      "dtypes: float64(4), int32(13), int64(2)\n",
      "memory usage: 8.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Showing The Info of The DataFrame and Ensure That There are no Object DType Left in The DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features and Outcome\n",
    "X = df.drop('type',axis=1).values\n",
    "y = df.type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [27649 28033 28223 ... 79013 79014 79015] TEST: [    0     1     2 ... 44998 45841 46455]\n",
      "TRAIN: [    0     1     2 ... 44998 45841 46455] TEST: [27649 28033 28223 ... 79013 79014 79015]\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Folds Cross-Validator.\n",
    "# Provides Train/Test Indices To Split Data in Train/Test Sets.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39508, 18) (39508,) (39508, 18) (39508,)\n"
     ]
    }
   ],
   "source": [
    "# Showing The Shape of Train/Test Sets\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Performance:\n",
      "Accuracy: 0.2755644426445277\n",
      "Accuracy-Score :27.56\n",
      "Precision: 0.2755644426445277\n",
      "Precision-Score :27.56\n",
      "Recall: 1.0\n",
      "Recall-Score :100.00\n",
      "F1-Score: 0.4320666732810795\n",
      "F1-Score :43.21\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "# Import The Necessary Libraries For LogisticRegression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Creating an Instance of The LogisticRegression Class\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fitting The Model on The Training Data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting The Target Variable For The Test Data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculating The Performance Metrics of The Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1_score2 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "# Printing The Performance Metrics\n",
    "print('Logistic Regression Model Performance:')\n",
    "print('Accuracy:', accuracy)\n",
    "print ('Accuracy-Score :{:.2f}'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('Precision:', precision)\n",
    "print ('Precision-Score :{:.2f}'.format(precision_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('Recall:', recall)\n",
    "print ('Recall-Score :{:.2f}'.format(recall_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('F1-Score:', f1_score2)\n",
    "print ('F1-Score :{:.2f}'.format(f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Accuracy: 0.588159360129594\n",
      "Accuracy-Score :58.82\n",
      "Precision: 0.6491820024245857\n",
      "Precision-Score :64.92\n",
      "Recall: 0.588159360129594\n",
      "Recall-Score :58.82\n",
      "F1-Score: 0.6051089264394816\n",
      "F1-Score :60.51\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "# Import The Necessary Libraries For DecisionTreeClassifier.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Creating an Instance of The DecisionTreeClassifier Class\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting The Model on The Training Data\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Predicting The Target Variable For The Test Data\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calculating The Performance Metrics of The Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1_score2 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "# Printing The Performance Metrics\n",
    "print('Decision Tree Classifier:')\n",
    "print('Accuracy:', accuracy)\n",
    "print ('Accuracy-Score :{:.2f}'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('Precision:', precision)\n",
    "print ('Precision-Score :{:.2f}'.format(precision_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('Recall:', recall)\n",
    "print ('Recall-Score :{:.2f}'.format(recall_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('F1-Score:', f1_score2)\n",
    "print ('F1-Score :{:.2f}'.format(f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Class:\n",
      "Accuracy: 0.2878910600384732\n",
      "Accuracy-Score :28.79\n",
      "Precision: 0.2482357797979103\n",
      "Precision-Score :24.82\n",
      "Recall: 0.36620625261598894\n",
      "Recall-Score :36.62\n",
      "F1-Score: 0.21706815016076209\n",
      "F1-Score :21.71\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Creating an Instance of The GaussianNB Class\n",
    "nb = GaussianNB()\n",
    "\n",
    "# fitting the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# predicting the target variable for the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculating The Performance Metrics of The Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1_score2 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "# Printing The Performance Metrics\n",
    "print('Gaussian NB Class:')\n",
    "print('Accuracy:', accuracy)\n",
    "print ('Accuracy-Score :{:.2f}'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('Precision:', precision)\n",
    "print ('Precision-Score :{:.2f}'.format(precision_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('Recall:', recall)\n",
    "print ('Recall-Score :{:.2f}'.format(recall_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('F1-Score:', f1_score2)\n",
    "print ('F1-Score :{:.2f}'.format(f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc50dbfa31ee75264b2521872f6237496636f13b1f9f605e4ec44e63e6a740ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
