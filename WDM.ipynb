{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read The DataSet.\n",
    "df = pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show All Columns.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Unnecessary Column From The DataSet.  \n",
    "df=df.drop(['id','region', 'region_url', 'VIN','url','image_url','description','county'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Missing Value.\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79016, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing The DataFrame Shape.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79016 entries, 31 to 426836\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   price         79016 non-null  int64  \n",
      " 1   year          79016 non-null  float64\n",
      " 2   manufacturer  79016 non-null  object \n",
      " 3   model         79016 non-null  object \n",
      " 4   condition     79016 non-null  object \n",
      " 5   cylinders     79016 non-null  object \n",
      " 6   fuel          79016 non-null  object \n",
      " 7   odometer      79016 non-null  float64\n",
      " 8   title_status  79016 non-null  object \n",
      " 9   transmission  79016 non-null  object \n",
      " 10  drive         79016 non-null  object \n",
      " 11  size          79016 non-null  object \n",
      " 12  type          79016 non-null  object \n",
      " 13  paint_color   79016 non-null  object \n",
      " 14  state         79016 non-null  object \n",
      " 15  lat           79016 non-null  float64\n",
      " 16  long          79016 non-null  float64\n",
      " 17  posting_date  79016 non-null  object \n",
      "dtypes: float64(4), int64(1), object(13)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Showing The Info of The DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>odometer</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.901600e+04</td>\n",
       "      <td>79016.000000</td>\n",
       "      <td>7.901600e+04</td>\n",
       "      <td>79016.000000</td>\n",
       "      <td>79016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.958972e+04</td>\n",
       "      <td>2008.474575</td>\n",
       "      <td>1.244541e+05</td>\n",
       "      <td>38.434362</td>\n",
       "      <td>-92.646525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.389146e+07</td>\n",
       "      <td>9.995538</td>\n",
       "      <td>2.431615e+05</td>\n",
       "      <td>5.653717</td>\n",
       "      <td>17.602460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-81.838232</td>\n",
       "      <td>-159.719900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.950000e+03</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>7.300000e+04</td>\n",
       "      <td>34.945300</td>\n",
       "      <td>-104.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000e+03</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.140000e+05</td>\n",
       "      <td>39.336100</td>\n",
       "      <td>-86.658280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.750000e+04</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.554140e+05</td>\n",
       "      <td>42.278811</td>\n",
       "      <td>-80.081908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.736929e+09</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>82.252826</td>\n",
       "      <td>139.691700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price          year      odometer           lat          long\n",
       "count  7.901600e+04  79016.000000  7.901600e+04  79016.000000  79016.000000\n",
       "mean   7.958972e+04   2008.474575  1.244541e+05     38.434362    -92.646525\n",
       "std    1.389146e+07      9.995538  2.431615e+05      5.653717     17.602460\n",
       "min    0.000000e+00   1900.000000  0.000000e+00    -81.838232   -159.719900\n",
       "25%    4.950000e+03   2006.000000  7.300000e+04     34.945300   -104.899400\n",
       "50%    9.000000e+03   2011.000000  1.140000e+05     39.336100    -86.658280\n",
       "75%    1.750000e+04   2014.000000  1.554140e+05     42.278811    -80.081908\n",
       "max    3.736929e+09   2022.000000  1.000000e+07     82.252826    139.691700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing The Describe of The DataSet\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing If There Any Duplicated Row\n",
    "sum(df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete The Duplicated Row in The DataSet.\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'year', 'manufacturer', 'model', 'condition', 'cylinders',\n",
       "       'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'size',\n",
       "       'type', 'paint_color', 'state', 'lat', 'long', 'posting_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing The Column-Name in The DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries For Using LabelEncoder.\n",
    "from sklearn import preprocessing\n",
    "# LabelEncoder Can Be Used to Normalize Labels.\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Label Encoder and Return Encoded Labels.\n",
    "df[['size','manufacturer', 'model', 'condition','cylinders', 'fuel', 'title_status', 'transmission','drive', 'type', 'paint_color', 'state',\n",
    "       'posting_date']] = df[['size','manufacturer', 'model', 'condition','cylinders', 'fuel', 'title_status', 'transmission','drive','type', 'paint_color', 'state',\n",
    "       'posting_date']].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Features By Scaling Each Feature to a Given Range.\n",
    "df[\"odometer\"] = np.sqrt(preprocessing.minmax_scale(df[\"odometer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price           0\n",
       "year            0\n",
       "manufacturer    0\n",
       "model           0\n",
       "condition       0\n",
       "cylinders       0\n",
       "fuel            0\n",
       "odometer        0\n",
       "title_status    0\n",
       "transmission    0\n",
       "drive           0\n",
       "size            0\n",
       "type            0\n",
       "paint_color     0\n",
       "state           0\n",
       "lat             0\n",
       "long            0\n",
       "posting_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure That There are No Null Values Left in The DataFrame.\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78837 entries, 31 to 426836\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   price         78837 non-null  int64  \n",
      " 1   year          78837 non-null  float64\n",
      " 2   manufacturer  78837 non-null  int64  \n",
      " 3   model         78837 non-null  int64  \n",
      " 4   condition     78837 non-null  int64  \n",
      " 5   cylinders     78837 non-null  int64  \n",
      " 6   fuel          78837 non-null  int64  \n",
      " 7   odometer      78837 non-null  float64\n",
      " 8   title_status  78837 non-null  int64  \n",
      " 9   transmission  78837 non-null  int64  \n",
      " 10  drive         78837 non-null  int64  \n",
      " 11  size          78837 non-null  int64  \n",
      " 12  type          78837 non-null  int64  \n",
      " 13  paint_color   78837 non-null  int64  \n",
      " 14  state         78837 non-null  int64  \n",
      " 15  lat           78837 non-null  float64\n",
      " 16  long          78837 non-null  float64\n",
      " 17  posting_date  78837 non-null  int64  \n",
      "dtypes: float64(4), int64(14)\n",
      "memory usage: 11.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Showing The Info of The DataFrame and Ensure That There are no Object DType Left in The DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features and Outcome\n",
    "X = df.drop('type',axis=1).values\n",
    "y = df.type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [26986 27614 27995 ... 78834 78835 78836] TEST: [    0     1     2 ... 44896 45735 46349]\n",
      "TRAIN: [    0     1     2 ... 44896 45735 46349] TEST: [26986 27614 27995 ... 78834 78835 78836]\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Folds Cross-Validator.\n",
    "# Provides Train/Test Indices To Split Data in Train/Test Sets.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39419, 17) (39419,) (39418, 17) (39418,)\n"
     ]
    }
   ],
   "source": [
    "# Showing The Shape of Train/Test Sets\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Performance:\n",
      "Accuracy: 0.30734689735653764\n",
      "Accuracy-Score :30.73\n",
      "Precision: 0.4243332572378631\n",
      "Precision-Score :42.43\n",
      "Recall: 0.39094517409403334\n",
      "Recall-Score :39.09\n",
      "F1-Score: 0.27602348273663097\n",
      "F1-Score :27.60\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "# Import The Necessary Libraries For LogisticRegression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Creating an Instance of The LogisticRegression Class\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "\n",
    "# Fitting The Model on The Training Data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting The Target Variable For The Test Data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculating The Performance Metrics of The Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1_score2 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "# Printing The Performance Metrics\n",
    "print('Logistic Regression Model Performance:')\n",
    "print('Accuracy:', accuracy)\n",
    "print ('Accuracy-Score :{:.2f}'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('Precision:', precision)\n",
    "print ('Precision-Score :{:.2f}'.format(precision_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('Recall:', recall)\n",
    "print ('Recall-Score :{:.2f}'.format(recall_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('F1-Score:', f1_score2)\n",
    "print ('F1-Score :{:.2f}'.format(f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Accuracy: 0.5863564868841646\n",
      "Accuracy-Score :58.64\n",
      "Precision: 0.6402839277942317\n",
      "Precision-Score :64.03\n",
      "Recall: 0.5863564868841646\n",
      "Recall-Score :58.64\n",
      "F1-Score: 0.5990416931440571\n",
      "F1-Score :59.90\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "# Import The Necessary Libraries For DecisionTreeClassifier.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Creating an Instance of The DecisionTreeClassifier Class\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting The Model on The Training Data\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Predicting The Target Variable For The Test Data\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calculating The Performance Metrics of The Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1_score2 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "# Printing The Performance Metrics\n",
    "print('Decision Tree Classifier:')\n",
    "print('Accuracy:', accuracy)\n",
    "print ('Accuracy-Score :{:.2f}'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('Precision:', precision)\n",
    "print ('Precision-Score :{:.2f}'.format(precision_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('Recall:', recall)\n",
    "print ('Recall-Score :{:.2f}'.format(recall_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('F1-Score:', f1_score2)\n",
    "print ('F1-Score :{:.2f}'.format(f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Class:\n",
      "Accuracy: 0.2945862296412806\n",
      "Accuracy-Score :29.46\n",
      "Precision: 0.2564367373920003\n",
      "Precision-Score :25.64\n",
      "Recall: 0.37471360805447096\n",
      "Recall-Score :37.47\n",
      "F1-Score: 0.22145014455784193\n",
      "F1-Score :22.15\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Creating an Instance of The GaussianNB Class\n",
    "nb = GaussianNB()\n",
    "\n",
    "# fitting the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# predicting the target variable for the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculating The Performance Metrics of The Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1_score2 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "# Printing The Performance Metrics\n",
    "print('Gaussian NB Class:')\n",
    "print('Accuracy:', accuracy)\n",
    "print ('Accuracy-Score :{:.2f}'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('Precision:', precision)\n",
    "print ('Precision-Score :{:.2f}'.format(precision_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('Recall:', recall)\n",
    "print ('Recall-Score :{:.2f}'.format(recall_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))\n",
    "print('F1-Score:', f1_score2)\n",
    "print ('F1-Score :{:.2f}'.format(f1_score(y_test, y_pred,average='weighted', labels=np.unique(y_pred))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc50dbfa31ee75264b2521872f6237496636f13b1f9f605e4ec44e63e6a740ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
